\chapter{Not remotely classical problems}


% \clearemptydoublepage
\section{The sushi bar problem}

This problem was inspired by a problem proposed by Kenneth Reek \cite{reek}.
Imagine a sushi bar with 5 seats.  If you arrive while there is an
empty seat, you can take a seat immediately.  But if you arrive when
all 5 seats are full, that means that all of them are dining together,
and you will have to wait for the entire party to leave before you
sit down.

Puzzle: write code for customers entering and
leaving the sushi bar that enforces these requirements.

\clearemptydoublepage
\subsection {Sushi bar hint}

Here are the variables I used:

\begin{lstlisting}[title={Sushi bar hint}]{}
eating = waiting = 0
mutex = Semaphore(1)
block = Semaphore(0)
must_wait = False
\end{lstlisting}

{\tt eating} and {\tt waiting} keep track of the number of
threads sitting at the bar and waiting.  {\tt mutex} protects
both counters.  {\tt must\_wait} indicates that the bar is (or
has been) full, som incoming customers have to block
on {\tt block}.


\clearemptydoublepage
\subsection {Sushi bar non-solution}

Here is an incorrect solution Reek uses to illustrate one
of the difficulties of this problem.

\begin{lstlisting}[title={Sushi bar non-solution}]{}
mutex.wait()
if must_wait:
    waiting += 1
    mutex.signal()
    block.wait()

    mutex.wait()      # reacquire mutex (*\label{sushi1}*)
    waiting -= 1

eating += 1
must_wait = (eating == 5)
mutex.signal()

# eat sushi

mutex.wait()
eating -= 1
if eating == 0:
    n = min(5, waiting)
    block.signal(n)
    must_wait = False
mutex.signal()
\end{lstlisting}

Puzzle: what's wrong with this solution?


\clearemptydoublepage
\subsection {Sushi bar non-solution}

The problem is at Line~\ref{sushi1}.  If a customer arrives
while the bar is full, he has to give up the mutex while he
waits so that other customers can leave.  When the last customer
leaves, she signals {\tt block}, which wakes up at least some
of the waiting customers, and clears {\tt must\_wait}.

But when the customers wake up, they have to get the mutex
back, and that means they have to compete with incoming new
threads.  If new threads arrive and get the mutex first,
they could take all the seats before the waiting threads.
This is not just a question of injustice; it is possible for more
than 5 threads to be in the critical section concurrently, which
violates the synchronization constraints.

Reek provides two solutions to this problem, which appear
in the next two sections.

Puzzle: see if you can come up with two different correct solutions!

Hint: neither solution uses any additional variables.

\clearemptydoublepage
\subsection {Sushi bar solution \#1}

The only reason a waiting customer has to reacquire the mutex
is to update the state of {\tt eating} and {\tt waiting}, so
one way to solve the problem is to make the departing customer,
who already has the mutex, do the updating.

\begin{lstlisting}[title={Sushi bar solution \#1}]{}
mutex.wait()
if must_wait:
    waiting += 1
    mutex.signal()
    block.wait()
else:
    eating += 1
    must_wait = (eating == 5)
    mutex.signal()

# eat sushi

mutex.wait()
eating -= 1
if eating == 0:
    n = min(5, waiting)
    waiting -= n
    eating += n
    must_wait = (eating == 5)
    block.signal(n)
mutex.signal()
\end{lstlisting}

When the last departing customer releases the mutex, 
{\tt eating} has already been updated, so newly arriving customers
see the right state and block if necessary.  Reek calls this
pattern ``I'll do it for you,'' because the departing thread
is doing work that seems, logically, to belong to the waiting
threads.

A drawback of this approach is that is it a little more difficult
to confirm that the state is being updated correctly.


\clearemptydoublepage
\subsection {Sushi bar solution \#2}

Reek's alternative solution is based on the counterintuitive
notion that we can transfer a mutex from one thread to another!
In other words, one thread can acquire a lock and then another
thread can release it.  As long as both threads understand
that the lock has been transferred, there is nothing wrong with
this.

\begin{lstlisting}[title={Sushi bar solution \#2}]{}
mutex.wait()
if must_wait:
    waiting += 1
    mutex.signal()
    block.wait()     # when we resume, we have the mutex
    waiting -= 1

eating += 1
must_wait = (eating == 5)
if waiting and not must_wait:
    block.signal()            # and pass the mutex
else:
    mutex.signal()

# eat sushi

mutex.wait()
eating -= 1
if eating == 0: must_wait = False

if waiting and not must_wait:
    block.signal()            # and pass the mutex
else:
    mutex.signal()
\end{lstlisting}

If there are fewer than 5 customers at the bar and no one waiting, an
entering customer just increments {\tt eating} and releases the
mutex.  The fifth customer sets {\tt must\_wait}.

If {\tt must\_wait} is set, entering customers block until the last
customer at the bar clears {\tt must\_wait} and signals {\tt block}.
It is understood that the signaling thread gives up the mutex and the
waiting thread receives it.  Keep in mind, though, that this is an
invariant understood by the programmer, and documented in the
comments, but not enforced by the semantics of semaphores.  It is up
to us to get it right.

When the waiting thread resumes, we understand that it has
the mutex.  If there are other threads waiting,
it signals {\tt block} which, again,
passes the mutex to a waiting thread.  This process
continues, with each thread passing the mutex to the next until
there are no more chairs or no more waiting threads.  In either
case, the last thread releases the mutex and goes to sit down.

Reek calls this pattern ``Pass the baton,'' since the mutex
is being passed from one thread to the next like a baton in a
relay race.
One nice thing about this solution is that it is easy to confirm
that updates to {\tt eating} and {\tt waiting} are consistent.
A drawback is that it is harder to confirm that the mutex is
being used correctly.


% \clearemptydoublepage
\section{The child care problem}

Max Hailperin wrote this problem for his textbook {\em Operating
Systems and Middleware} \cite{hailperin}.  At a child care center,
state regulations require that there is always one adult present for
every three children.

Puzzle: Write code for child threads and adult threads that enforces
this constraint in a critical section.


\clearemptydoublepage
\subsection {Child care hint}

Hailperin suggests that you can {\em almost} solve this problem
with one semaphore.

\begin{lstlisting}[title={Child care hint}]{}
multiplex = Semaphore(0)
\end{lstlisting}

{\tt multiplex} counts the number of tokens available, where each token
allows a child thread to enter.  As adults enter, they signal {\tt
multiplex} three times; as they leave, they {\tt wait} three times.
But there is a problem with this solution.

Puzzle: what is the problem?


\clearemptydoublepage
\subsection {Child care non-solution}

Here is what the adult code looks like in Hailperin's non-solution:

\begin{lstlisting}[title={Child care non-solution (adult)}]{}
multiplex.signal(3)

# critical section

multiplex.wait()
multiplex.wait()
multiplex.wait()
\end{lstlisting}

The problem is a potential deadlock.  Imagine that there are
three children and two adults in the child care center.  The
value of {\tt multiplex} is 3, so either adult should be able
to leave.  But if both adults start to leave at the same time,
they might divide the available tokens between them, and both
block.

Puzzle: solve this problem with a minimal change.


\clearemptydoublepage
\subsection {Child care solution}

Adding a mutex solves the problem:

\begin{lstlisting}[title={Child care solution (adult)}]{}
multiplex.signal(3)

# critical section

mutex.wait()
    multiplex.wait()
    multiplex.wait()
    multiplex.wait()
mutex.signal()
\end{lstlisting}

Now the three {\tt wait} operations are atomic.  If there
are three tokens available, the thread that gets the mutex
will get all three tokens and exit.  If there are fewer
tokens available, the first thread will block in the mutex
and subsequent threads will queue on the mutex.

\subsection {Extended child care problem}

One feature of this solution is that an adult thread waiting to leave
can prevent child threads from entering.

Imagine that there are 4 children and two adults, so the value of the
multiplex is 2.  If one of the adults tries to leave, she will take
two tokens and then block waiting for the third.  If a child thread
arrives, it will wait even though it would be legal to enter.
From the point of view of the adult trying to leave, that might
be just fine, but if you are trying to maximize the utilization
of the child care center, it's not.

Puzzle: write a solution to this problem that avoids unnecessary
waiting.

Hint: think about the dancers in Section~\ref{dancers}.



\clearemptydoublepage
\subsection {Extended child care hint}

Here are the variables I used in my solution:

\begin{lstlisting}[title={Extended child care hint}]{}
children = adults = waiting = leaving = 0
mutex = Semaphore(1)
childQueue = Semaphore(0)
adultQueue = Semaphore(0)
\end{lstlisting}

{\tt children}, {\tt adults}, {\tt waiting} and {\tt leaving}
keep track of the number of children, adults, children waiting
to enter, and adults waiting to leave; they are protected by
{\tt mutex}.

Children wait on {\tt childQueue} to enter, if necessary.
Adults wait on {\tt adultQueue} to leave.



\clearemptydoublepage
\subsection {Extended child care solution}

This solution is more complicated than
Hailperin's elegant solution, but it is mostly a combination
of patterns we have seen before: a scoreboard, two queues,
and ``I'll do it for you''.

Here is the child code:

\begin{lstlisting}[title={Extended child care solution (child)}]{}
mutex.wait()
    if children < 3 * adults:
        children++
        mutex.signal()
    else:
        waiting++
        mutex.signal()
        childQueue.wait()

# critical section

mutex.wait()
    children--
    if leaving and children <= 3 * (adults-1):
        leaving--
        adults--
        adultQueue.signal() 
mutex.signal()
\end{lstlisting}

As children enter, they check whether there are enough adults
and either (1) increment {\tt children} and enter or (2) increment
{\tt waiting} and block.
When they exit, they check for an adult thread waiting to leave and
signal it if possible.

\newpage
Here is the code for adults:

\begin{lstlisting}[title={Extended child care solution (adult)}]{}
mutex.wait()
    adults++
    if waiting:
        n = min(3, waiting)
        childQueue.signal(n)
        waiting -= n
        children += n
mutex.signal()

# critical section

mutex.wait()
    if children <= 3 * (adults-1):
        adults--
        mutex.signal()
    else:
        leaving++
        mutex.signal()
        adultQueue.wait() 
\end{lstlisting}

As adults enter, they signal waiting children, if any.  Before they
leave, they check whether there are enough adults left.  If so, they
decrement {\tt adults} and exit.  Otherwise they increment {\tt
leaving} and block.  While an adult thread is waiting to leave, it
counts as one of the adults in the critical section, so additional
children can enter.





\newpage
\section{The room party problem}

I wrote this problem while I was at Colby College.  One semester
there was a controversy over an allegation by a student that someone
from the Dean of Students Office had searched his room in his
absence.  Although the allegation was public, the Dean of Students
wasn't able to comment on the case, so we never found out what
really happened.  I wrote this problem to tease a friend of mine,
who was the Dean of Student Housing.

The following synchronization constraints apply to students
and the Dean of Students:

\begin{enumerate}

\item Any number of students can be in a room at the same
time.

\item The Dean of Students can only enter a room if there
are no students in the room (to conduct a search) or if
there are more than 50 students in the room (to break up
the party).

\item While the Dean of Students is in the room, no additional
students may enter, but students may leave.

\item The Dean of Students may not leave the room until all
students have left.

\item There is only one Dean of Students, so you do not have
to enforce exclusion among multiple deans.

\end{enumerate}

Puzzle: write synchronization code for students and for the
Dean of Students that enforces all of these constraints.


\clearemptydoublepage
\subsection {Room party hint}

\begin{lstlisting}[title={Room party hint}]{}
students = 0                
dean = 'not here'           
mutex = Semaphore(1)
turn = Semaphore(1)
clear = Semaphore(0)
lieIn = Semaphore(0)
\end{lstlisting}

{\tt students} counts the number of students in the room,
and {\tt dean} is the state of the Dean, which can also be
``waiting'' or ``in the room''.
{\tt mutex} protects {\tt students} and {\tt dean}, so this
is yet another example of a scoreboard.

{\tt turn} is a turnstile that keeps students from entering
while the Dean is in the room.

{\tt clear} and {\tt lieIn} are used as rendezvouses between
a student and the Dean (which is a whole other kind of scandal!).


\clearemptydoublepage
\subsection {Room party solution}

This problem is hard.  I worked through a lot of versions before
I got to this one.  The version that appeared in the first edition
was mostly correct, but occasionally the Dean would enter the
room and then find that he could neither search nor break up the
party, so he would have to skulk off in embarrassed silence.

Matt Tesch wrote a solution that spared this humiliation, but the
result was complicated enough that we had a hard time convincing
ourselves that it was correct.  But that solution led me to this one,
which is a bit more readable.

\begin{lstlisting}[title={Room party solution (dean)}]{}
mutex.wait()
    if students > 0 and students < 50:
        dean = 'waiting'
	mutex.signal()
	lieIn.wait()     # and get mutex from the student.

    # students must be 0 or >= 50     (*\label{roomparty1}*)

    if students >= 50:
        dean = 'in the room'
        breakup()
	turn.wait()      # lock the turnstile
        mutex.signal()
	clear.wait()     # and get mutex from the student.
	turn.signal()    # unlock the turnstile

    else:                # students must be 0
        search()

dean = 'not here'
mutex.signal() 
\end{lstlisting}

When the Dean arrives, there are three cases: if there are students in
the room, but not 50 or more, the Dean has to wait.  If there are 50
or more, the Dean breaks up the party and waits for the students to
leave.  If there are no students, the Dean searches and leaves.

In the first two cases, the Dean has to wait for a rendezvous with a
student, so he has to give up {\tt mutex} to avoid a deadlock.  When
the Dean wakes up, he has to modify the scoreboard, so he needs to get
the mutex back.  This is similar to the situation we saw in the Sushi
Bar problem.  The solution I chose is the ``Pass the baton'' pattern.

\newpage
\begin{lstlisting}[title={Room party solution (student)}]{}
mutex.wait()
    if dean == 'in the room':
        mutex.signal()
        turn.wait()
        turn.signal()
        mutex.wait()

    students += 1

    if students == 50 and dean == 'waiting':
        lieIn.signal()             # and pass mutex to the dean
    else:
        mutex.signal()

party()

mutex.wait()
    students -= 1

    if students == 0 and dean == 'waiting':
        lieIn.signal()         # and pass mutex to the dean
    elif students == 0 and dean == 'in the room':
        clear.signal()         # and pass mutex to the dean
    else:
        mutex.signal()
\end{lstlisting}

There are three cases where a student might have to signal the Dean.
If the Dean is waiting, then the 50th student in or the last one out
has to signal {\tt lieIn}.  If the Dean is in the room (waiting for
all the students to leave), the last student out signals {\tt clear}.
In all three cases, it is understood that the mutex passes from the
student to the Dean.

One part of this solution that may not be obvious is how we know at
Line~\ref{roomparty1} of the Dean's code that {\tt students} must be 0
or not less than 50.  The key is to realize that there are only two
ways to get to this point: either the first conditional was false,
which means that {\tt students} is either 0 or not less than 50; or
the Dean was waiting on {\tt lieIn} when a student signaled, which
means, again, that {\tt students} is either 0 or not less than 50.


\clearemptydoublepage
\section{The Senate Bus problem}

This problem was originally based on the Senate bus at Wellesley
College.  Riders come to a bus stop and wait for a bus.  When the bus
arrives, all the waiting riders invoke {\tt boardBus}, but anyone who
arrives while the bus is boarding has to wait for the next bus.  The
capacity of the bus is 50 people; if there are more than 50 people
waiting, some will have to wait for the next bus.

When all the waiting riders have boarded,
the bus can invoke {\tt depart}.  If the bus arrives when there
are no riders, it should depart immediately.

Puzzle: Write synchronization code that enforces all of these
constraints.


\clearemptydoublepage
\subsection {Bus problem hint}

Here are the variables I used in my solution:

\begin{lstlisting}[title={Bus problem hint}]{}
riders = 0
mutex = Semaphore(1)
multiplex = Semaphore(50)
bus = Semaphore(0)
allAboard = Semaphore(0)
\end{lstlisting}

{\tt mutex} protects {\tt riders}, which keeps track of
how many riders are waiting;
{\tt multiplex} makes sure there are no more than 50 riders
in the boarding area.

Riders wait on
{\tt bus}, which gets signaled when the bus arrives.  The
bus waits on {\tt allAboard}, which gets signaled by the last
student to board.


\clearemptydoublepage
\subsection {Bus problem solution \#1}

Here is the code for the bus.  Again, we are using the
``Pass the baton'' pattern.

\begin{lstlisting}[title={Bus problem solution (bus)}]{}
mutex.wait()
if riders > 0:
    bus.signal()        # and pass the mutex
    allAboard.wait()    # and get the mutex back
mutex.signal()

depart()
\end{lstlisting}

When the bus arrives, it gets {\tt mutex}, which
prevents late arrivals from entering the boarding area.  If there
are no riders, it departs immediately.  Otherwise, it signals {\tt bus}
and waits for the riders to board.

Here is the code for the riders:

\begin{lstlisting}[title={Bus problem solution (riders)}]{}
multiplex.wait()
    mutex.wait()
        riders += 1
    mutex.signal()

    bus.wait()              # and get the mutex
multiplex.signal()

boardBus()

riders -= 1
if riders == 0:
    allAboard.signal() 
else:
    bus.signal()            # and pass the mutex
\end{lstlisting}

The multiplex controls the number of riders in the waiting area,
although strictly speaking, a rider doesn't enter the waiting
area until she increments {\tt riders}.

Riders wait on {\tt bus} until the bus arrives.  When a rider
wakes up, it is understood that she has the mutex.
After boarding, each rider decrements {\tt riders}.  If there
are more riders waiting, the boarding rider signals {\tt bus}
and pass the mutex to the next rider.  The last rider signals
{\tt allAboard} and passes the mutex back to the bus.

Finally, the bus releases the mutex and departs.

Puzzle: can you find a solution to this problem using the
``I'll do it for you'' pattern?


\clearemptydoublepage
\subsection {Bus problem solution \#2}

Grant Hutchins came up with this solution, which uses fewer
variables than the previous one, and doesn't involve passing
around any mutexes.  Here are the variables:

\begin{lstlisting}[title={Bus problem solution \#2 (initialization)}]{}
waiting = 0
mutex = new Semaphore(1)
bus = new Semaphore(0)
boarded = new Semaphore(0)
\end{lstlisting}

{\tt waiting} is the number of riders in the boarding area,
which is protected by {\tt mutex}.  {\tt bus} signals when the
bus has arrived; {\tt boarded} signals that a rider has boarded.

Here is the code for the bus.

\begin{lstlisting}[title={Bus problem solution (bus)}]{}
mutex.wait()
n = min(waiting, 50)
for i in range(n):
    bus.signal()
    boarded.wait()

waiting = max(waiting-50, 0)
mutex.signal()

depart()
\end{lstlisting}

The bus gets the {\tt mutex} and holds it throughout the boarding
process.  The loop signals each rider in turn and waits for her to
board.  By controlling the number of signals, the bus prevents
more than 50 riders from boarding.

When all the riders have boarded, the bus updates {\tt
waiting}, which is an example of the ``I'll do it for you'' pattern.

The code for the riders uses two
simple patterns: a mutex and a rendezvous.

\begin{lstlisting}[title={Bus problem solution (riders)}]{}
mutex.wait()
     waiting += 1
mutex.signal()

bus.wait()
board()
boarded.signal()
\end{lstlisting}

Challenge: if riders arrive while the bus is boarding, they
might be annoyed if you make them wait for the next one.  Can you
find a solution that allows late arrivals to board without violating
the other constraints?


\clearemptydoublepage
\section{The Faneuil Hall problem}

This problem was written by Grant Hutchins, who was inspired
by a friend who took her
Oath of Citizenship at Faneuil Hall in Boston.

``There are three kinds of threads: immigrants, spectators, and a one
judge.  Immigrants must wait in line, check in, and then sit down.  At
some point, the judge enters the building.  When the judge is in the
building, no one may enter, and the immigrants may not leave.
Spectators may leave.  Once all immigrants check in, the judge can
confirm the naturalization.  After the confirmation, the immigrants
pick up their certificates of U.S. Citizenship.  The judge leaves at
some point after the confirmation.  Spectators may now enter as
before.  After immigrants get their certificates, they may leave.''

To make these requirements more specific, let's give the threads
some functions to execute, and put constraints on those functions.

\begin{itemize}

\item Immigrants must invoke {\tt enter}, {\tt checkIn}, {\tt sitDown},
{\tt swear}, {\tt getCertificate} and {\tt leave}.

\item The judge invokes {\tt enter}, {\tt confirm} and {\tt leave}.

\item Spectators invoke {\tt enter}, {\tt spectate} and {\tt leave}.

\item While the judge is in the building, no one may {\tt enter}
and immigrants may not {\tt leave}.

\item The judge can not {\tt confirm} until all immigrants who have
invoked {\tt enter} have also invoked {\tt checkIn}.

\item Immigrants can not {\tt getCertificate} until the judge
has executed {\tt confirm}.

\end{itemize}

\clearemptydoublepage
\subsection {Faneuil Hall Problem Hint}

\begin{lstlisting}[title={Faneuil Hall problem hint}]{}
noJudge = Semaphore(1)
entered = 0
checked = 0
mutex = Semaphore(1)
confirmed = Semaphore(0)
\end{lstlisting}

{\tt noJudge} acts as a turnstile for incoming immigrants and
spectators; it also protects {\tt entered}, which counts the
number of immigrants in the room.  {\tt checked} counts the
number of immigrants who have checked in; it is protected by
{\tt mutex}.

{\tt confirmed} signals that the judge has executed {\tt confirm}.


\clearemptydoublepage
\subsection {Faneuil Hall problem solution}

Here is the code for immigrants:

\begin{lstlisting}[title={Faneuil Hall problem solution (immigrant)}]{}
noJudge.wait()
enter()
entered++
noJudge.signal()

mutex.wait()
checkIn()
checked++

if judge = 1 and entered == checked:
    allSignedIn.signal()              # and pass the mutex
else:
    mutex.signal()

sitDown()
confirmed.wait()

swear()
getCertificate()

noJudge.wait()
leave()
noJudge.signal()
\end{lstlisting}

Immigrants pass through a turnstile when they enter; while the
judge is in the room, the turnstile is locked.

After entering, immigrants have to get {\tt mutex} to check 
in and update {\tt checked}.  If there is a judge waiting, the
last immigrant to check in signals {\tt allSignedIn} and passes
the mutex to the judge.

Here is the code for the judge:

\begin{lstlisting}[title={Faneuil Hall problem solution (judge)}]{}
noJudge.wait()
mutex.wait()

enter()
judge = 1

if entered > checked:
    mutex.signal()
    allSignedIn.wait()               # and get the mutex back.

confirm()
confirmed.signal(checked)
entered = checked = 0

leave()
judge = 0

mutex.signal()
noJudge.signal()
\end{lstlisting}

The judge holds {\tt noJudge} to bar immigrants and spectators
from entering, and {\tt mutex} so he can access {\tt entered}
and {\tt checked}.

If the judge arrives at an instant when everyone who has
entered has also checked in, she can proceed immediately.  Otherwise,
she has to give up the mutex and wait.  When the last immigrant
checks in and signals {\tt allSignedIn}, it is understood that the
judge will get the mutex back.

After invoking {\tt confirm}, the judge signals {\tt confirmed}
once for every immigrant who has checked in, and then resets
the counters (an example of ``I'll do it for you'').
Then the judge leaves and releases {\tt mutex} and {\tt noJudge}.

After the judge signals {\tt confirmed}, immigrants invoke
{\tt swear} and {\tt getCertificate} concurrently, and then
wait for the {\tt noJudge} turnstile to open before leaving.

The code for spectators is easy; the only constraint they have
to obey is the {\tt noJudge} turnstile.

\begin{lstlisting}[title={Faneuil Hall problem solution (spectator)}]{}
noJudge.wait()
enter()
noJudge.signal()

spectate()

leave()
\end{lstlisting}

Note: in this solution it is possible for immigrants to get stuck,
after they get their certificate, by another judge coming to swear
in the next batch of immigrants.  If that happens, they might have
to wait through another swearing in-ceremony.

Puzzle: modify this solution to handle the additional constraint
that after the judge leaves, all immigrants who have been sworn
in must leave before the judge can enter again.


\clearemptydoublepage
\subsection {Extended Faneuil Hall Problem Hint}

My solution uses the following additional variables:

\begin{lstlisting}[title={Faneuil Hall problem hint}]{}
exit = Semaphore(0)
allGone = Semaphore(0)
\end{lstlisting}

Since the extended problem involves an additional rendezvous,
we can solve it with two semaphores.

One other hint: I found it useful to use the ``pass the baton''
pattern again.


\clearemptydoublepage
\subsection {Extended Faneuil Hall problem solution}

The top half of this solution is the same as before.  The
difference starts at Line~\ref{fanexit}.  Immigrants wait
here for the judge to leave.

\begin{lstlisting}[title={Faneuil Hall problem solution (immigrant)}]{}
noJudge.wait()
enter()
entered++
noJudge.signal()

mutex.wait()
checkIn()
checked++

if judge = 1 and entered == checked:
    allSignedIn.signal()              # and pass the mutex
else:
    mutex.signal()

sitDown()
confirmed.wait()

swear()
getCertificate()

exit.wait()                          # and get the mutex(*\label{fanexit}*)
leave()
checked--
if checked == 0:
    allGone.signal()                 # and pass the mutex
else:
    exit.signal()                    # and pass the mutex
\end{lstlisting}

For the judge, the difference starts at Line~\ref{fanjudge}.
When the judge is ready to leave, she can't release {\tt noJudge},
because that would allow more immigrants, and possibly another
judge, to enter.  Instead, she signals {\tt exit}, which allows
one immigrant to leave, and passes {\tt mutex}.

The immigrant that gets the signal decrements {\tt checked} and
then passes the baton to the next immigrant.  The last immigrant
to leave signals {\tt allGone} and passes the mutex back to the
judge.  This pass-back is not strictly necessary, but it has
the nice feature that the judge releases both {\tt mutex}
and {\tt noJudge} to end the phase cleanly.

\newpage
\begin{lstlisting}[title={Faneuil Hall problem solution (judge)}]{}
noJudge.wait()
mutex.wait()

enter()
judge = 1

if entered > checked:
    mutex.signal()
    allSignedIn.wait()               # and get the mutex back.

confirm()
confirmed.signal(checked)
entered = 0

leave()
judge = 0

exit.signal()                       # and pass the mutex(*\label{fanjudge}*)
allGone.wait()                      # and get it back
mutex.signal()
noJudge.signal()
\end{lstlisting}

The spectator code for the extended problem is unchanged.


\clearemptydoublepage
\section{Dining Hall problem}

This problem was written by Jon Pollack during my Synchronization
class at Olin College.  

Students in the dining hall invoke {\tt dine} and then {\tt leave}.
After invoking {\tt dine} and before invoking {\tt leave} a student is
considered ``ready to leave''.

The synchronization constraint that applies to students is that, in
order to maintain the illusion of social suave, a student may never
sit at a table alone.  A student is considered to be sitting alone
if everyone else who has invoked {\tt dine} invokes {\tt leave}
before she has finished {\tt dine}.

Puzzle: write code that enforces this constraint.


\clearemptydoublepage
\subsection {Dining Hall problem hint}

\begin{lstlisting}[title={Dining Hall problem hint}]{}
eating = 0
readyToLeave = 0
mutex = Semaphore(1)
okToLeave = Semaphore(0)
\end{lstlisting}

{\tt eating} and {\tt readyToLeave} are
counters protected by {\tt mutex}, so this is the usual
scoreboard pattern.

If a student is ready to leave, but another student would be
left alone at the table, she waits on
{\tt okToLeave} until another student changes
the situation and signals.


\clearemptydoublepage
\subsection {Dining Hall problem solution}

If you analyze the constraints, you will realize that there
is only one situation where a student has to wait, if there is
one student eating and one student who wants to leave.  But
there are two ways to get out of this situation: another
student might arrive to eat, or the dining student might 
finish.

In either case, the student who signals the waiting student
updates the counters, so the waiting student doesn't have
to get the mutex back.  This is another example of the
the ``I'll do it for you'' pattern.

\begin{lstlisting}[title={Dining Hall problem solution}]{}
getFood()

mutex.wait()
eating++
if eating == 2 and readyToLeave == 1:
    okToLeave.signal()
    readyToLeave--
mutex.signal()

dine()

mutex.wait()
eating--
readyToLeave++

if eating == 1 and readyToLeave == 1:
    mutex.signal()
    okToLeave.wait()
elif eating == 0 and readyToLeave == 2:
    okToLeave.signal()
    readyToLeave -= 2
    mutex.signal()
else:
    readyToLeave--
    mutex.signal()

leave()
\end{lstlisting}

When is student is checking in, if she sees one student
eating and one waiting to leave, she lets the waiter off the
hook and decrements {\tt readyToLeave} for him.

\newpage
After dining, the student checks three cases:

\begin{itemize}

\item If there is only one student left eating, the departing student
has to give up the mutex and wait.

\item If the departing student finds that someone is waiting for
her, she signals him and updates the counter for both of them.

\item Otherwise, she just decrements {\tt readyToLeave} and leaves.

\end{itemize}


\subsection{Extended Dining Hall problem}

The Dining Hall problem gets a little more challenging if we
add another step.  As students come to lunch they
invoke {\tt getFood}, {\tt dine} and then {\tt leave}.
After invoking {\tt getFood} and before invoking {\tt dine},
a student is considered ``ready to eat''.  Similarly, after
invoking {\tt dine} a student is considered ``ready to leave''.

The same synchronization constraint applies: a student may never sit
at a table alone.  A student is considered to be sitting alone if
either

\begin{itemize}

\item She invokes {\tt dine} while there is no one else at the table
and no one ready to eat, or

\item everyone else who has invoked {\tt dine} invokes {\tt leave}
before she has finished {\tt dine}.

\end{itemize}

Puzzle: write code that enforces these constraints.


\clearemptydoublepage
\subsection {Extended Dining Hall problem hint}

Here are the variables I used in my solution:

\begin{lstlisting}[title={Extended Dining Hall problem hint}]{}
readyToEat = 0
eating = 0
readyToLeave = 0
mutex = Semaphore(1)
okToSit = Semaphore(0)
okToLeave = Semaphore(0)
\end{lstlisting}

{\tt readyToEat}, {\tt eating} and {\tt readyToLeave} are
counters, all protected by {\tt mutex}.

If a student is in a situation where she cannot proceed, she
waits on
{\tt okToSit} or {\tt okToLeave} until another student changes
the situation and signals.

I also used a per-thread variable named {\tt hasMutex} to help
keep track of whether or not a thread holds the mutex.


\clearemptydoublepage
\subsection {Extended Dining Hall problem solution}

Again, if we analyze the constraints, we realize that there is
only one situation where a student who is ready to eat has
to wait, if there is no one eating and no one else ready to
eat.  And the only way out is if someone else arrives who
is ready to eat.

\begin{lstlisting}[title={Extended Dining Hall problem solution}]{}
getFood()

mutex.wait()
readyToEat++
if eating == 0 and readyToEat == 1:
    mutex.signal()
    okToSit.wait()
elif eating == 0 and readyToEat == 2:
    okToSit.signal()
    readyToEat -= 2
    eating += 2
    mutex.signal()
else:
    readyToEat--
    eating++
    if eating == 2 and readyToLeave == 1:
        okToLeave.signal()
        readyToLeave--
    mutex.signal()

dine()

mutex.wait()
eating--
readyToLeave++
if eating == 1 and readyToLeave == 1:
    mutex.signal()
    okToLeave.wait()
elif eating == 0 and readyToLeave == 2:
    okToLeave.signal()
    readyToLeave -= 2
    mutex.signal()
else:
    readyToLeave--
    mutex.signal()

leave()
\end{lstlisting}

As in the previous solution, I used the ``I'll do it for you''
pattern so that a waiting student doesn't have to get the mutex
back.

The primary difference between this solution and the previous
one is that the first student who arrives at an empty table
has to wait, and the second student allows both students to
proceed.  It either case, we don't have to check for students
waiting to leave, since no one can leave an empty table!



%\clearemptydoublepage
%\section{Party problem}

%Description

%\clearemptydoublepage
%\subsection {Party problem hint}

%\begin{lstlisting}[title={Party problem hint}]{}
%\end{lstlisting}

%\clearemptydoublepage
%\subsection {Party problem solution}

%\begin{lstlisting}[title={Party problem solution}]{}
%\end{lstlisting}




\chapter{Synchronization in Python}
\label{pysync}

By using pseudocode, we have avoided some of the ugly
details of synchronization in the real world.  In this chapter
we'll look at real synchronization code in Python; in the
next chapter we'll look at C.

Python provides a reasonably pleasant multithreading environment,
complete with Semaphore objects.  It has
a few foibles, but there is some cleanup code in Appendix~\ref{cleanup}
that makes things a little better.

Here is a simple example:

\begin{lstlisting}[title={}]{}
from threading_cleanup import *

class Shared:
    def __init__(self):
        self.counter = 0

def child_code(shared):
    while True:
        shared.counter += 1
        print shared.counter
        time.sleep(0.5)

shared = Shared()
children = [Thread(child_code, shared) for i in range(2)]
for child in children: child.join()
\end{lstlisting}

The first line runs the cleanup code from Appendix~\ref{cleanup};
I will leave this line out of the other examples.

{\tt Shared} defines an object type that will contain shared variables.
Global variables are also shared between threads, but we won't
use any in these examples.  Threads that are local in the sense
that they are declared inside a function are also local in the
sense that they are thread-specific.

The child code is an infinite loop that increments {\tt counter},
prints the new value, and then sleeps for 0.5 seconds.

The parent thread creates {\tt shared} and two children,
then waits for the children to exit (which in this case, they won't).

\section{Mutex checker problem}

Diligent students of synchronization will notice that the
children make unsynchronized updates to {\tt counter}, which
is not safe!  If you run this program, you might see some
errors, but you probably won't.  The nasty thing about synchronization
errors is that they are unpredictable, which means that even
extensive testing may not reveal them.

To detect errors, it is often necessary to automate the search.
In this case, we can detect errors by keeping track of the values
of {\tt counter}.

\begin{lstlisting}[title={}]{}
class Shared:
    def __init__(self, end=10):
        self.counter = 0
        self.end = end
        self.array = [0]* self.end

def child_code(shared):
    while True:
        if shared.counter >= shared.end: break
        shared.array[shared.counter] += 1
        shared.counter += 1

shared = Shared(10)
children = [Thread(child_code, shared) for i in range(2)]
for child in children: child.join()
print shared.array
\end{lstlisting}

In this example, {\tt shared} contains a list (misleadingly
named {\tt array}) that keeps track of the number of times
each value of counter is used.
Each time through the loop, the children check {\tt counter}
and quit if it exceeds {\tt end}.  If not, they use {\tt counter}
as an index into {\tt array} and increment the corresponding
entry.  Then they increment {\tt counter}.

If everything works correctly, each entry in the array should
be incremented exactly once.  When the children exit, the parent
returns from {\tt join} and prints the value of {\tt array}.
When I ran the program, I got
%
\begin{verbatim}
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
\end{verbatim}
%
which is disappointingly correct.  If we increase the size of
the array, we might expect more errors, but it also gets harder
to check the result.

\newpage
We can automate the checker by making
a histogram of the results in the array:

\begin{lstlisting}[title={}]{}
class Histogram(dict):
    def __init__(self, seq=[]):
        for item in seq:
            self[item] = self.get(item, 0) + 1

print Histogram(shared.array)
\end{lstlisting}

Now when I run the program, I get

\begin{verbatim}
{1: 10}
\end{verbatim}
%
which means that the value 1 appeared 10 times, as expected.  No
errors so far, but if we make {\tt end} bigger, things get more
interesting:

\begin{verbatim}
end = 100, {1: 100}
end = 1000, {1: 1000}
end = 10000, {1: 10000}
end = 100000, {1: 27561, 2: 72439}
\end{verbatim}
%
Oops!  When {\tt end} is big enough that there are a lot of
context switches between the children, we start to get synchronization
errors.  In this case, we get a {\em lot} of errors, which suggests
that the program falls into a recurring pattern where threads are 
consistently interrupted in the critical section.

This example demonstrates one of the dangers of synchronization
errors, which is that they may be rare, but they are not random.
If an error occurs one time in a million, that doesn't mean it
won't happen a million times in a row.

Puzzle: add synchronization code to this program to enforce
exclusive access to the shared variables.  You can download the
code in this section from \url{greenteapress.com/semaphores/counter.py}


\clearemptydoublepage
\subsection {Mutex checker hint}

Here is the version of {\tt Shared} I used:

\begin{lstlisting}[title={}]{}
class Shared:
    def __init__(self, end=10):
        self.counter = 0
        self.end = end
        self.array = [0]* self.end
        self.mutex = Semaphore(1)
\end{lstlisting}

The only change is the Semaphore named {\tt mutex}, which should
come as no surprise.

\clearemptydoublepage
\subsection {Mutex checker solution}

Here is my solution:

\begin{lstlisting}[title={}]{}
def child_code(shared):
    while True:
        shared.mutex.wait()
        if shared.counter < shared.end:
            shared.array[shared.counter] += 1
            shared.counter += 1
            shared.mutex.signal()
        else:
            shared.mutex.signal()
            break
\end{lstlisting}

Although this is not the most difficult synchronization problem
in this book, you might have found it tricky to get the details
right.  In particular, it is easy to forget to signal the mutex
before breaking out of the loop, which would cause a deadlock.

I ran this solution with {\tt end = 1000000}, and got the
following result:

\begin{verbatim}
{1: 1000000}
\end{verbatim}

Of course, that doesn't mean my solution is correct, but it is
off to a good start.


\clearemptydoublepage
\section {The coke machine problem}

The following program simulates producers and consumers
adding and removing cokes from a coke machine:

\begin{lstlisting}[title={}]{}
import random

class Shared:
    def __init__(self, start=5):
        self.cokes = start

def consume(shared):
    shared.cokes -= 1
    print shared.cokes

def produce(shared):
    shared.cokes += 1
    print shared.cokes

def loop(shared, f, mu=1):
    while True:
        t = random.expovariate(1.0/mu)
        time.sleep(t)
        f(shared)

shared = Shared()
fs = [consume]*2 + [produce]*2 
threads = [Thread(loop, shared, f) for f in fs]
for thread in threads: thread.join()
\end{lstlisting}

The capacity is 10 cokes, and that the machine is initially
half full.  So the shared variable {\tt cokes} is 5.

The program creates 4 threads, two producers and two consumers.
They both run {\tt loop}, but producers invoke {\tt produce}
and consumers invoke {\tt consume}.  These functions make
unsynchronized access to a shared variable, which is a no-no.

Each time through the loop, producers and consumers sleep for a
duration chosen from an exponential distribution with mean {\tt mu}.
Since there are two producers and two consumers, two cokes get added
to the machine per second, on average, and two get removed.

So on average the number of cokes is constant, but in the short
run in can vary quite widely.  If you run the program for a
while, you will probably see the value of {\tt cokes} dip
below zero, or climb above 10.  Of course, neither of these
should happen.

Puzzle: add code to this program to enforce the following
synchronization constraints:

\begin{itemize}

\item Access to {\tt cokes} should be mutually exclusive.

\item If the number of cokes is zero, consumers should block
until a coke is added.

\item If the number of cokes is 10, producers should block
until a coke is removed.

\end{itemize}

You can download the program from
\url{greenteapress.com/semaphores/coke.py}


\clearemptydoublepage
\subsection {Coke machine hint}

Here are the shared variables I used in my solution:

\begin{lstlisting}[title={}]{}
class Shared:
    def __init__(self, start=5, capacity=10):
        self.cokes = Semaphore(start)
        self.slots = Semaphore(capacity-start)
        self.mutex = Semaphore(1)
\end{lstlisting}

{\tt cokes} is a Semaphore now (rather than a simple integer), 
which makes it tricky to print its value.  Of course, you
should never access the value of a Semaphore, and Python in
its usual do-gooder way doesn't provide any of the cheater
methods you see in some implementations.

But you might find it interesting to know that the value
of a Semaphore is stored in a private attribute named
{\tt \_Semaphore\_\_value}.  Also, in case you don't know,
Python doesn't actually enforce any restriction on access to
private attributes.  You should never access it, of course,
but I thought you might be interested.

Ahem.


\clearemptydoublepage
\subsection {Coke machine solution}

If you've read the rest of this book, you should have had no
trouble coming up with something at least as good as this:

\begin{lstlisting}[title={}]{}
def consume(shared):
    shared.cokes.wait()
    shared.mutex.wait()
    print shared.cokes.value()
    shared.mutex.signal()
    shared.slots.signal()

def produce(shared):
    shared.slots.wait()
    shared.mutex.wait()
    print shared.cokes._Semaphore__value
    shared.mutex.signal()
    shared.cokes.signal()
\end{lstlisting}

If you run this program for a while, you should be able to confirm
that the number of cokes in the machine is never negative or greater
than 10.  So this solution seems to be correct.

So far.


\chapter{Synchronization in C}
\label{csync}

In this section we will write a multithreaded, synchronized
program in C.  Appendix~\ref{ccleanup} provides some of the utility
code I use to make the C code a little more palatable.  The
examples in this section depend on that code.

\section{Mutual exclusion}

We'll start by defining a structure that contains shared
variables:

\begin{lstlisting}[title={}]{}
typedef struct {
  int counter;
  int end;
  int *array;
} Shared;

Shared *make_shared (int end)
{
  int i;
  Shared *shared = check_malloc (sizeof (Shared));

  shared->counter = 0;
  shared->end = end;

  shared->array = check_malloc (shared->end * sizeof(int));
  for (i=0; i<shared->end; i++) {
    shared->array[i] = 0;
  }
  return shared;
}
\end{lstlisting}

{\tt counter} is a shared variable that will be incremented by
concurrent threads until it reaches {\tt end}.  We will use
{\tt array} to check for synchronization errors by keeping track
of the value of {\tt counter} after each increment.

\subsection{Parent code}

Here is the code the parent thread uses to create threads
and wait for them to complete:

\begin{lstlisting}[title={}]{}
int main ()
{
  int i;
  pthread_t child[NUM_CHILDREN];

  Shared *shared = make_shared (100000);

  for (i=0; i<NUM_CHILDREN; i++) {
    child[i] = make_thread (entry, shared);
  }

  for (i=0; i<NUM_CHILDREN; i++) {
    join_thread (child[i]);
  }

  check_array (shared);
  return 0;
}
\end{lstlisting}

The first loop creates the child threads; the second loop waits
for them to complete.  When the last child has finished, the parent
invokes {\tt check\_array} to check for errors.
{\tt make\_thread} and {\tt join\_thread} are defined in
Appendix~\ref{ccleanup}.

\subsection{Child code}

Here is the code that is executed by each of the children:

\begin{lstlisting}[title={}]{}
void child_code (Shared *shared)
{
  while (1) {
    if (shared->counter >= shared->end) {
      return;
    }
    shared->array[shared->counter]++;
    shared->counter++;
  }
}
\end{lstlisting}

Each time through the loop, the child threads use {\tt counter}
as an index into {\tt array} and increment the corresponding element.
Then they increment {\tt counter} and check to see if they're done.

\subsection{Synchronization errors}

If everything works correctly, each element of the array should be
incremented once.  So to check for errors, we can just count the
number of elements that are not 1:

\begin{lstlisting}[title={}]{}
void check_array (Shared *shared)
{
  int i, errors=0;

  for (i=0; i<shared->end; i++) {
    if (shared->array[i] != 1) errors++;
  }
  printf ("%d errors.\n", errors);
}
\end{lstlisting}

You can download this program (including the cleanup code) from
\url{greenteapress.com/semaphores/counter.c}

If you compile and run the program, you should see output like this:

\begin{verbatim}
Starting child at counter 0
10000
20000
30000
40000
50000
60000
70000
80000
90000
Child done.
Starting child at counter 100000
Child done.
Checking...
0 errors.
\end{verbatim}

Of course, the interaction of the children depends on details
of your operating system and also other programs running on your
computer.  In the example shown here, one thread ran all the way
from 0 to {\tt end} before the other thread got started, so it is
not surprising that there were no synchronization errors.

But as {\tt end} gets bigger, there are more context switches between
the children.  On my system I start to see errors when
{\tt end} is 100,000,000.

Puzzle: use semaphores to enforce exclusive access to the shared
variables and run the program again to confirm that there are
no errors.

\clearemptydoublepage
\subsection{Mutual exclusion hint}

Here is the version of {\tt Shared} I used in my solution:

\begin{lstlisting}[title={}]{}
typedef struct {
  int counter;
  int end;
  int *array;
  Semaphore *mutex;  (*\label{declaremutex}*)
} Shared;

Shared *make_shared (int end)
{
  int i;
  Shared *shared = check_malloc (sizeof (Shared));

  shared->counter = 0;
  shared->end = end;

  shared->array = check_malloc (shared->end * sizeof(int));
  for (i=0; i<shared->end; i++) {
    shared->array[i] = 0;
  }
  shared->mutex = make_semaphore(1);  (*\label{initmutex}*)
  return shared;
}
\end{lstlisting}

Line~\ref{declaremutex} declares {\tt mutex} as a Semaphore;
Line~\ref{initmutex} initializes the mutex with the value 1.


\clearemptydoublepage
\subsection{Mutual exclusion solution}

Here is the synchronized version of the child code:

\begin{lstlisting}[title={}]{}
void child_code (Shared *shared)
{
  while (1) {
    sem_wait(shared->mutex);
    if (shared->counter >= shared->end) {
      sem_signal(shared->mutex);
      return;
    }

    shared->array[shared->counter]++;
    shared->counter++;
    sem_signal(shared->mutex);
  }
}
\end{lstlisting}

There is nothing too surprising here; the only tricky thing
is to remember to release the mutex before the {\tt return}
statement.

You can download this solution from 
\url{greenteapress.com/semaphores/counter_mutex.c}


\clearemptydoublepage
\section{Make your own semaphores}
\label{makeyourown}

The most commonly used synchronization tools for programs that use
Pthreads are mutexes and condition variables, not semaphores.  For an
explanation of these tools, I recommend Butenhof's {\em Programming
with POSIX Threads} \cite{butenhof}.

Puzzle: read about mutexes and condition variables, and then
use them to write an implementation of semaphores.

You might want to use the following utility code in your solutions.
Here is my wrapper for Pthreads mutexes:

\begin{lstlisting}[title={}]{}
typedef pthread_mutex_t Mutex;

Mutex *make_mutex ()
{
  Mutex *mutex = check_malloc (sizeof(Mutex));
  int n = pthread_mutex_init (mutex, NULL);
  if (n != 0) perror_exit ("make_lock failed"); 
  return mutex;
}

void mutex_lock (Mutex *mutex)
{
  int n = pthread_mutex_lock (mutex);
  if (n != 0) perror_exit ("lock failed");
}

void mutex_unlock (Mutex *mutex)
{
  int n = pthread_mutex_unlock (mutex);
  if (n != 0) perror_exit ("unlock failed");
}
\end{lstlisting}

\newpage
And my wrapper for Pthread condition variables:

\begin{lstlisting}[title={}]{}
typedef pthread_cond_t Cond;

Cond *make_cond ()
{
  Cond *cond = check_malloc (sizeof(Cond)); 
  int n = pthread_cond_init (cond, NULL);
  if (n != 0) perror_exit ("make_cond failed");
  return cond;
}

void cond_wait (Cond *cond, Mutex *mutex)
{
  int n = pthread_cond_wait (cond, mutex);
  if (n != 0) perror_exit ("cond_wait failed");
}

void cond_signal (Cond *cond)
{
  int n = pthread_cond_signal (cond);
  if (n != 0) perror_exit ("cond_signal failed");
}
\end{lstlisting}



\clearemptydoublepage
\subsection{Semaphore implementation hint}

Here is the structure definition I used for my semaphores:

\begin{lstlisting}[title={}]{}
typedef struct {
  int value, wakeups;
  Mutex *mutex;
  Cond *cond;
} Semaphore;
\end{lstlisting}

{\tt value} is the value of the semaphore.  {\tt wakeups} counts
the number of pending signals; that is, the number of threads
that have been woken but have not yet resumed execution.  The reason
for wakeups is to make sure that our semaphores have
Property 3, described in Section~\ref{props}.

{\tt mutex} provides exclusive access to {\tt value} and
{\tt wakeups}; {\tt cond} is the condition variable threads
wait on if they wait on the semaphore.

Here is the initialization code for this structure:

\begin{lstlisting}[title={}]{}
Semaphore *make_semaphore (int value)
{
  Semaphore *semaphore = check_malloc (sizeof(Semaphore));
  semaphore->value = value;
  semaphore->wakeups = 0;
  semaphore->mutex = make_mutex ();
  semaphore->cond = make_cond ();
  return semaphore;
}
\end{lstlisting}


\clearemptydoublepage
\subsection{Semaphore implementation}

Here is my implementation of semaphores using Pthread's mutexes
and condition variables:

\begin{lstlisting}[title={}]{}
void sem_wait (Semaphore *semaphore)
{
  mutex_lock (semaphore->mutex);                 (*\label{sementer}*)
  semaphore->value--;

  if (semaphore->value < 0) {
    do {                                                (*\label{dowhile}*)
      cond_wait (semaphore->cond, semaphore->mutex);
    } while (semaphore->wakeups < 1);
    semaphore->wakeups--;
  }
  mutex_unlock (semaphore->mutex);
}

void sem_signal (Semaphore *semaphore)
{
  mutex_lock (semaphore->mutex);
  semaphore->value++;

  if (semaphore->value <= 0) {
    semaphore->wakeups++;
    cond_signal (semaphore->cond);
  }
  mutex_unlock (semaphore->mutex);
}
\end{lstlisting}

Most of this is straightforward; the only thing that might be 
tricky is the {\tt do...while} loop at Line~\ref{dowhile}.
This is an unusual way to use a condition variable, but in
this case it is necessary.

Puzzle: why can't we replace this {\tt do...while} loop
with a {\tt while} loop?

\clearemptydoublepage
\subsection{Semaphore implementation detail}

With a {\tt while} loop, this implementation would not have
Property 3.  It would be possible for a thread to signal
and then run around and catch its own signal.

With the {\tt do...while} loop, it is guaranteed\footnote{Well,
  almost.  It turns out that a well-timed spurious wakeup (see
  \url{http://en.wikipedia.org/wiki/Spurious_wakeup}) can violate this
  guarantee.} that when a thread signals, one of the waiting threads
will get the signal, even if another thread gets the mutex at
Line~\ref{sementer} before one of the waiting threads resumes.


\bibliographystyle{plain}
\bibliography{book}

\appendix

\chapter{Cleaning up Python threads}
\label{cleanup}

Compared to a lot of other threading environments, Python threads are
pretty good, but there are a couple of features that annoy me.
Fortunately, you can fix them with a little clean-up code.

\section{Semaphore methods}

First, the methods for Python semaphores are called {\tt acquire}
and {\tt release}, which is a perfectly reasonable choice, but
after working on this book for a couple of years, I am used
to {\tt signal} and {\tt wait}.  Fortunately, I can have it
my way by subclassing the version of Semaphore in the
{\tt threading} module:

\begin{lstlisting}[title={Semaphore name change}]{}
import threading
 
class Semaphore(threading._Semaphore):
    wait = threading._Semaphore.acquire
    signal = threading._Semaphore.release
\end{lstlisting}

Once this class is defined, you can create and manipulate Semaphores
using the syntax in this book.

\begin{lstlisting}[title={Semaphore example}]{}
mutex = Semaphore()
mutex.wait()
mutex.signal()
\end{lstlisting}

\section{Creating threads}

The other feature of the {\tt threading} module that annoys
me is the interface for creating and starting threads.  The
usual way requires keyword arguments and two steps:

\begin{lstlisting}[title={Thread example (standard way)}]{}
import threading

def function(x, y, z):
    print x, y, z

thread = threading.Thread(target=function, args=[1, 2, 3])
thread.start()
\end{lstlisting}

In this example, creating the thread has no immediate effect.
But when you invoke {\tt start}, the new thread executes
the target function with the given arguments.
This is great if you need to do something with the thread
before it starts, but I almost never do.
Also, I think the keyword arguments {\tt target} and {\tt args}
are awkward.

Fortunately, we can solve both of these problems with four
lines of code.

\begin{lstlisting}[title={Cleaned-up Thread class}]{}
class Thread(threading.Thread):
    def __init__(self, t, *args):
        threading.Thread.__init__(self, target=t, args=args)
        self.start()
\end{lstlisting}

Now we can create threads with a nicer interface, and they
start automatically:

\begin{lstlisting}[title={Thread example (my way)}]{}
thread = Thread(function, 1, 2, 3)
\end{lstlisting}

This also lends itself to an idiom I like, which is to create
multiple Threads with a list comprehension:

\begin{lstlisting}[title={Multiple thread example}]{}
threads = [Thread(function, i, i, i) for i in range(10)]
\end{lstlisting}

\section{Handling keyboard interrupts}

One other problem with the {\tt threading} class is that 
{\tt Thread.join} can't be interrupted by Ctrl-C, which
generates the signal {\tt SIGINT}, which Python translates
into a KeyboardInterrupt.

\newpage
So, if you write the following program:

\begin{lstlisting}[title={Unstoppable program}]{}
import threading, time

class Thread(threading.Thread):
    def __init__(self, t, *args):
        threading.Thread.__init__(self, target=t, args=args)
        self.start()

def parent_code():
    child = Thread(child_code, 10)
    child.join()

def child_code(n=10):
    for i in range(n):
        print i
        time.sleep(1)
    
parent_code()
\end{lstlisting}

You will find that it cannot be interrupted with Ctrl-C or
a {\tt SIGINT}\footnote{At the time of this writing, this
bug had been reported and assigned number 1167930, but it was
open and unassigned (\url{https://sourceforge.net/projects/python/}).}.

My workaround for this problem uses {\tt os.fork} and {\tt os.wait},
so it only works on UNIX and Macintosh.  Here's how it works:
before creating new threads, the program invokes {\tt watcher},
which forks a new process.  The new process returns and executes
the rest of the program.  The original process waits for the
child process to complete, hence the name {\tt watcher}:

\begin{lstlisting}[title={The watcher}]{}
import threading, time, os, signal, sys

class Thread(threading.Thread):
    def __init__(self, t, *args):
        threading.Thread.__init__(self, target=t, args=args)
        self.start()

def parent_code():
    child = Thread(child_code, 10)
    child.join()

def child_code(n=10):
    for i in range(n):
        print i
        time.sleep(1)

def watcher():
    child = os.fork()
    if child == 0: return
    try:
        os.wait()
    except KeyboardInterrupt:
        print 'KeyboardInterrupt'
        os.kill(child, signal.SIGKILL)
    sys.exit()

watcher()
parent_code()
\end{lstlisting}

If you run this version of the program, you should be able
to interrupt it with Ctrl-C.  I am not sure, but I think it
is guaranteed that the {\tt SIGINT} is delivered to the
watcher process, so that's one less thing the
parent and child threads have to deal with.

I keep all this code in a file named {\tt threading\_cleanup.py},
which you can download from
\url{greenteapress.com/semaphores/threading\_cleanup.py}


The examples in Chapter~\ref{pysync} are presented with the understanding
that this code executes prior to the example code.


\chapter{Cleaning up POSIX threads}
\label{ccleanup}

In this section, I present some utility code I use to make
multithreading in C a little more pleasant.  The examples in
Section~\ref{csync} are based on this code.

Probably the most popular threading standard used with C is
POSIX Threads, or Pthreads for short.  The POSIX standard defines
a thread model and an interface for creating and controlling
threads.  Most versions of UNIX provide an implementation of
Pthreads.

\section{Compiling Pthread code}

Using Pthreads is like using most C libraries:

\begin{itemize}

\item You include headers files at the beginning of your
program.

\item You write code that calls functions defined by Pthreads.

\item When you compile the program, you link it with the
Pthread library.

\end{itemize}

For my examples, I include the following headers:

\begin{lstlisting}[title={Headers}]{}
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <semaphore.h>
\end{lstlisting}

The first two are standard; the third is for Pthreads and
the fourth is for semaphores.
To compile with the Pthread library in {\tt gcc}, you
can use the {\tt -l}
option on the command line:

\begin{lstlisting}[title={}]{}
gcc -g -O2 -o array array.c -lpthread
\end{lstlisting}

This compiles {\tt array.c} with debugging info and optimization,
links with the Pthread library, and generates an executable
named {\tt array}.

If you are used to a language like Python that provides exception
handling, you will probably be annoyed with languages like C that
require you to check for error conditions explicitly.  I often
mitigate this hassle by wrapping library function calls
together with their error-checking code inside my own functions.
For example, here is a version of {\tt malloc}
that checks the return value.

\begin{lstlisting}[title={}]{}
void *check_malloc(int size)
{
  void *p = malloc (size);
  if (p == NULL) {
    perror ("malloc failed");
    exit (-1);
  }
  return p;
}
\end{lstlisting}


\section{Creating threads}

I've done the same thing with the Pthread functions I'm going to use;
here's my wrapper for {\tt pthread\_create}.

\begin{lstlisting}[title={}]{}
pthread_t make_thread(void *(*entry)(void *), Shared *shared)
{
  int n;
  pthread_t thread;

  n = pthread_create (&thread, NULL, entry, (void *)shared);
  if (n != 0) {
    perror ("pthread_create failed");
    exit (-1);
  }
  return thread;
}
\end{lstlisting}

The return type from {\tt pthread\_create} is {\tt pthread\_t},
which you can think of as a handle for the new thread.  You
shouldn't have to worry about the implementation of {\tt pthread\_t},
but you do have to know that it has the semantics of a primitive
type\footnote{Like an integer, for example, which is what a
{\tt pthread\_t} is in all the implementations I know.}.  That
means that you can think of a thread handle as an immutable
value, so you can copy it or pass it by value without causing
problems.  I point this out now because it is not true for
semaphores, which I will get to in a minute.

If {\tt pthread\_create} succeeds, it returns 0 and my function
returns the handle of the new thread.
If an error occurs, {\tt pthread\_create} 
returns an error code and my function prints an error message
and exits.

The parameters of {\tt pthread\_create} take some
explaining.  Starting with the second,
{\tt Shared}
is a user-defined structure that contains shared variables.
The following {\tt typedef} statement creates the new type:

\begin{lstlisting}[title={}]{}
typedef struct {
  int counter;
} Shared;
\end{lstlisting}

In this case, the only shared variable is {\tt counter}.
{\tt make\_shared} allocates
space for a {\tt Shared} structure and initializes the contents:

\begin{lstlisting}[title={}]{}
Shared *make_shared ()
{
  int i;
  Shared *shared = check_malloc (sizeof (Shared));
  shared->counter = 0;
  return shared;
}
\end{lstlisting}

Now that we have a shared data structure, let's get back to
{\tt pthread\_create}.
The first parameter is a pointer to a function that takes
a {\tt void} pointer and returns a {\tt void} pointer.  If the syntax
for declaring this type makes your eyes bleed, you are not alone.
Anyway, the purpose of this parameter is to specify the function where
the execution of the new thread will begin.  By convention, this
function is named {\tt entry}:

\begin{lstlisting}[title={}]{}
void *entry (void *arg)
{
  Shared *shared = (Shared *) arg;
  child_code (shared);
  pthread_exit (NULL);
}
\end{lstlisting}

The parameter of {\tt entry} has to be declared as a {\tt void}
pointer, but in this program we know that it is really a pointer to a
{\tt Shared} structure, so we can typecast it accordingly and then
pass it along to {\tt child\_code}, which does the real work.

When {\tt child\_code} returns, we invoke {\tt pthread\_exit}
which can be used to pass a value to any thread (usually the
parent) that joins with this thread.  In this case, the child
has nothing to say, so we pass {\tt NULL}.


\section{Joining threads}

When one thread want to wait for another thread to complete,
it invokes {\tt pthread\_join}.
Here is my wrapper for {\tt pthread\_join}:

\begin{lstlisting}[title={}]{}
void join_thread (pthread_t thread)
{
  int ret = pthread_join (thread, NULL);
  if (ret == -1) {
    perror ("pthread_join failed");
    exit (-1);
  }
}
\end{lstlisting}

The parameter is the handle of the thread you want to wait for.
All my function does is call {\tt pthread\_join} and check the
result.


\section{Semaphores}

The POSIX standard specifies an interface for semaphores.
This interface is not part of Pthreads, but most UNIXes
that implement Pthreads also provide semaphores.  If you
find yourself with Pthreads and without semaphores, you
can make your own; see Section~\ref{makeyourown}.

POSIX semaphores have type {\tt sem\_t}.  You shouldn't have
to know about the implementation of this type, but you do
have to know that it has structure semantics, which means that
if you assign it to a variable you are making a copy of the
contents of a structure.  Copying a semaphore is almost certainly
a bad idea.  In POSIX, the behavior of the copy is undefined.

In my programs, I use capital letters to denote types with
structure semantics, and I always manipulate them with pointers.
Fortunately, it is easy to put a wrapper around {\tt sem\_t}
to make it behave like a proper object.  Here is the 
{\tt typedef} and the wrapper that creates and initializes
semaphores:

\begin{lstlisting}[title={}]{}
typedef sem_t Semaphore;

Semaphore *make_semaphore (int n)
{
  Semaphore *sem = check_malloc (sizeof(Semaphore));
  int ret = sem_init(sem, 0, n);
  if (ret == -1) {
    perror ("sem_init failed");
    exit (-1);    
  }
  return sem;
}
\end{lstlisting}

{\tt make\_semaphore} takes the initial value of the semaphore
as a parameter.  It allocates space for a Semaphore, initializes
it, and returns a pointer to {\tt Semaphore}.

{\tt sem\_init} uses old-style UNIX error reporting, which means
that it returns -1 if something went wrong.  Once nice thing
about these wrapper functions is that we don't have to remember
which functions use which reporting style.

With these definitions, we can write C code that almost looks
like a real programming language:

\begin{lstlisting}[title={}]{}
Semaphore *mutex = make_semaphore(1);
sem_wait(mutex);
sem_post(mutex);
\end{lstlisting}

Annoyingly, POSIX semaphores use {\tt post} instead of
{\tt signal}, but we can fix that:

\begin{lstlisting}[title={}]{}
int sem_signal(Semaphore *sem)
{
  return sem_post(sem);
}
\end{lstlisting}

That's enough cleanup for now.

\end{document}

